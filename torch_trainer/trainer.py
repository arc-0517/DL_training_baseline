import os
import torch
import torch.nn as nn
import torch.optim as optim
from tqdm import tqdm
from sklearn.metrics import accuracy_score
import pandas as pd

class Trainer(object):
    def __init__(self,
                 model: nn.Module):
        super(Trainer, self).__init__()

        self.model = model
        self.compiled = False

    def compile(self,
                ckpt_dir: str,
                loss_function: str = 'ce',
                optimizer: str = 'adam',
                scheduler: str = 'cosine',
                learnig_rate: float = 1e-4,
                epochs: int = 300,
                local_rank: int = 0):

        self.ckpt_dir = ckpt_dir
        os.makedirs(self.ckpt_dir, exist_ok=True)

        self.epochs = epochs
        
        # CUDA ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸ ë° ë””ë°”ì´ìŠ¤ ì„¤ì •
        if torch.cuda.is_available():
            try:
                self.device = f"cuda:{local_rank}"
                # ì‹¤ì œë¡œ CUDA ë””ë°”ì´ìŠ¤ê°€ ì‘ë™í•˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸
                test_tensor = torch.tensor([1.0]).to(self.device)
                print(f"CUDA ì‚¬ìš© ê°€ëŠ¥: {self.device}")
                print(f"GPU: {torch.cuda.get_device_name(local_rank)}")
            except Exception as e:
                print(f"CUDA ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                print("CPU ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
                self.device = "cpu"
        else:
            print("CUDAë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("CPU ëª¨ë“œë¡œ í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤.")
            self.device = "cpu"

        # ë””ë°”ì´ìŠ¤ ì •ë³´ ì¶œë ¥
        print(f"ğŸ¯ ì‚¬ìš© ë””ë°”ì´ìŠ¤: {self.device}")

        # ëª¨ë¸ì„ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
        try:
            self.model.to(self.device)
            print("ëª¨ë¸ì´ ë””ë°”ì´ìŠ¤ë¡œ ì„±ê³µì ìœ¼ë¡œ ì´ë™ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"ëª¨ë¸ ë””ë°”ì´ìŠ¤ ì´ë™ ì‹¤íŒ¨: {e}")
            # CPUë¡œ ê°•ì œ ì„¤ì •
            self.device = "cpu"
            self.model.to(self.device)
            print("ê°•ì œë¡œ CPU ëª¨ë“œë¡œ ì „í™˜í–ˆìŠµë‹ˆë‹¤.")

        # Define Optimizer
        if optimizer == 'adam':
            self.optimizer = optim.Adam(params=self.model.parameters(),
                                        lr=learnig_rate, weight_decay=1e-5)
        elif optimizer == 'sgd':
            self.optimizer = optim.SGD(params=self.model.parameters(),
                                        lr=learnig_rate, weight_decay=1e-5)
        elif optimizer == 'adamW':
            self.optimizer = optim.AdamW(params=self.model.parameters(),
                                        lr=learnig_rate, weight_decay=1e-5)
        else:
            raise ValueError('Provide a proper optimizer name')

        if scheduler == 'cosine':
            self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=self.epochs, eta_min=0.0001)

        # Define Loss function
        if loss_function == "ce":
            self.loss_function = nn.CrossEntropyLoss()
        elif loss_function == "mse":
            self.loss_function = nn.MSELoss()
        else:
            raise ValueError('Provide a proper loss function name')

        self.compiled = True
        
        # í•™ìŠµ í™˜ê²½ ì •ë³´ ì¶œë ¥
        print(f"\n í•™ìŠµ í™˜ê²½ ì„¤ì • ì™„ë£Œ:")
        print(f"   ë””ë°”ì´ìŠ¤: {self.device}")
        print(f"   ì˜µí‹°ë§ˆì´ì €: {optimizer}")
        print(f"   í•™ìŠµë¥ : {learnig_rate}")
        print(f"   ì—í¬í¬: {epochs}")
        print(f"   ì†ì‹¤í•¨ìˆ˜: {loss_function}")

    def train(self, epoch, data_loader):

        if not self.compiled:
            raise RuntimeError('Training not prepared')

        self._set_learning_phase(True)
        total_loss, total_num, train_bar = 0.0, 0, tqdm(data_loader)

        for inputs, targets in train_bar:
            inputs = inputs.to(self.device)
            targets = targets.to(self.device)
            pred = self.model(inputs)
            loss = self.loss_function(pred, targets)

            self.optimizer.zero_grad()
            loss.backward()
            self.optimizer.step()
            if hasattr(self, 'scheduler'):
                self.scheduler.step()

            total_num += data_loader.batch_size
            total_loss += loss.item() * data_loader.batch_size
            
            # CPU ì‚¬ìš© ì‹œì—ëŠ” ë” ìì„¸í•œ ì§„í–‰ ìƒí™© í‘œì‹œ
            device_info = "CPU" if self.device == "cpu" else f"GPU-{self.device}"
            train_bar.set_description('Train Epoch: [{}/{}] [{}], lr: {:.6f}, Loss: {:.4f}'.format(
                epoch, self.epochs, device_info, self.get_lr(self.optimizer), total_loss / total_num))
        return total_loss / total_num

    @torch.no_grad()
    def valid(self, epoch, data_loader):
        pred_list, label_list = [], []
        self._set_learning_phase(False)  # ìˆ˜ì •: True -> False (validation ëª¨ë“œ)
        total_loss, total_num, valid_bar = 0.0, 0, tqdm(data_loader)

        for inputs, targets in valid_bar:
            inputs = inputs.to(self.device)
            targets = targets.to(self.device)
            pred = self.model(inputs)

            _, predicted = torch.max(pred.data, 1)
            pred_list += predicted.tolist()
            label_list += targets.tolist()

            loss = self.loss_function(pred, targets)
            valid_acc = accuracy_score(pred_list, label_list)

            total_num += data_loader.batch_size
            total_loss += loss.item() * data_loader.batch_size
            
            device_info = "CPU" if self.device == "cpu" else f"GPU-{self.device}"
            valid_bar.set_description('Valid Epoch: [{}/{}] [{}], Loss: {:.4f}, Acc: {:.3f}'.format(
                epoch, self.epochs, device_info, total_loss / total_num, valid_acc))
        return total_loss / total_num, valid_acc

    @torch.no_grad()
    def test(self, epoch, data_loader):
        pred_list, label_list = [], []
        self._set_learning_phase(False)
        test_bar = tqdm(data_loader)

        for inputs, targets in test_bar:
            inputs = inputs.to(self.device)
            targets = targets.to(self.device)
            pred = self.model(inputs)

            _, predicted = torch.max(pred.data, 1)
            pred_list += predicted.tolist()
            label_list += targets.tolist()

            test_acc = accuracy_score(pred_list, label_list)
            device_info = "CPU" if self.device == "cpu" else f"GPU-{self.device}"
            test_bar.set_description('Test Epoch: [{}/{}] [{}], ACC: {:.3f}'.format(
                epoch, self.epochs, device_info, test_acc))
        return test_acc

    def save(self, epoch, results):
        # save statistics
        data_frame = pd.DataFrame(data=results, index=range(1, epoch + 1))
        data_frame.to_csv(self.ckpt_dir + '/log.csv', index_label='epoch')
        
        # ëª¨ë¸ ì €ì¥ ì‹œ ë””ë°”ì´ìŠ¤ ì •ë³´ë„ í•¨ê»˜ ì €ì¥
        torch.save({'epoch': epoch,
                    'state_dict': self.model.state_dict(),
                    'optimizer': self.optimizer.state_dict(),
                    'device': self.device},  # ë””ë°”ì´ìŠ¤ ì •ë³´ ì¶”ê°€
                    self.ckpt_dir + '/model_last.pth')

    def _set_learning_phase(self, train: bool = False):
        if train:
            self.model.train()
        else:
            self.model.eval()

    def get_lr(self, optimizer):
        for param_group in optimizer.param_groups:
            return param_group['lr']